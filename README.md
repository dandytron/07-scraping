# Scraping

## This is the seventh homework assignment for Lede Program 2025.

### It's three Jupyter notebooks: 

1. Retrieving Wikipedia Presidential data
2. Scraping the Le Monde front page (the most challenging)
3. Scraping an Arizona state website on third-party drivers license locations
4. Seaching a West Tennessee bankruptcy court database of cases

This assignment was meant to get us familiar with popular methods to scrape websites, parse data, and manipulate it.

- How to use BeautifulSoup, requests and more to grab data
- How to use Python and Pandas logic to manipulate and extract data
- Dump it in a CSV

To view these documents, you'll need to use Jupyter Notebook or Jupyter Lab.

1. Install Python: Make sure you have Python installed (Python 3.6 or later recommended).

2. Install Jupyter and other required libtaries: Open your command prompt or terminal and run:

`pip install notebook jupyterlab pandas matplotlib altair`


### Option 1: Jupyter Notebook

1. Launch Jupyter Notebook: In your terminal, type:

`jupyter notebook`

2. This will open a browser window showing the Jupyter Notebook dashboard where you can create or open notebooks.

### Option 2: Jupyter Lab (Alternative)

1. Launch Jupyter Lab: In your terminal, type:

`jupyter lab`

2. This opens Jupyter Lab, a more advanced interface that includes notebooks, file browser, terminals, and other tools in a flexible layout.

### Using Either Interface

- Option 1: From the menu, select Cell → Run All
- Option 2: Press the keyboard shortcut Ctrl+Alt+Enter (or Cmd+Alt+Enter on Mac)
- Option 3: Click the "Fast Forward" button (▶▶) in the toolbar if available

Then, wait for execution to complete.

Cells are executed in sequence. A number in brackets [1] appears next to each cell when it completes.

After that, scroll through the notebook and behold my struggles.

Happy viewing!
